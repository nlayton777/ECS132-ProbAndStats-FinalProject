\documentclass[11pt]{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{pdfpages}
\usepackage{listings}
\usepackage{color}
\usepackage{color}
\usepackage{lmodern}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\pagestyle{headings}
\setlength{\oddsidemargin}{0in}
\setlength{\evensidemargin}{0in}
\setlength{\textheight}{9in}
\setlength{\textwidth}{6.5in}
\setlength{\topmargin}{-0.5in}
\setlength{\headheight}{14pt}
\renewcommand*\rmdefault{lmss}
\renewcommand*\contentsname{Table of Contents}
\lstset{language=R,
	aboveskip=3mm,
	belowskip=3mm,
	showstringspaces=false,
	%basicstyle={\small\ttfamily},
	basicstyle={\normalfont\ttfamily},
	numbers=left,
	numberstyle=\tiny\color{gray},
	keywordstyle=\color{blue},
	commentstyle=\color{dkgreen},
	stringstyle=\color{mauve},
	breaklines=true,
	breakatwhitespace=true,
	tabsize=4
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{\vspace{-3ex}\bf Final Project\\[2ex] 
       \normalsize ECS 132 --- Winter 2015}
\date{\today}
\author{\bf William Otwell (997371020)\\ \bf Rupali Saiya (997286348)\\ \bf Nicholas Layton(996933702)\\ \bf Syeda Inamdar(997323599)\\}

\begin{document}
\maketitle
\pagebreak
\tableofcontents
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Problem 1}
\label{sec:problem1}
\subsection{Part A: Comparison of Two Means}
\label{subsec:1a}
The bike sharing dataset provided by the UC Irvine (UCI) Machine Learning Repository allows us to analyze bike rental statistics during the years 2011 and 2012. We decided to analyze and compare the quantity of bike rentals on days during the months of March 2011 and March 2012 to gain insight as to how much the bike rental rates changed from one year to the next. In more formal terms, we estimated the difference between the average number of bikes rented in March 2011 and the average number of bikes rented in March 2012. To do so, we constructed a confidence interval from the sample provided by UCI to estimate the difference between the population means of the averages from each month. We first had to define our random variables before constructing our confidence interval. Below is a list of the random variables that we used:
\begin{itemize}
	\item $X$: the number of bikes rented on any given day in March 2011
	\item $Y$: the number of bikes rented on any given day in March 2012
	\item $\bar{X}$: the sample mean of the number of bikes rented per day in March 2011
	\item $\bar{Y}$: the sample mean of the number of bikes rented per day in March 2012
	\item $s_1$: the standard deviation of the number of bikes rented per day in March 2011
	\item $s_2$: the standard deviation of the number of bikes rented per day in March 2012
\end{itemize}
An important aspect worth noting is that the random variables $X$ and $Y$ are independent of one another. After defining our random variables, we had to construct our model for constructing the confidence interval. Our model turned out to be the following:
\begin{equation}
\bar{X} - \bar{Y} \pm (1.96) \sqrt{\frac{s_{1}^{2}}{n_1} + \frac{s_{2}^{2}}{n_2}}
\end{equation}
\dots where $n_1$ and $n_2$ were the number of days in March 2011 and March 2012 (respecfully) for which data was recorded. The R code that we developed to calculate this confidence interval can be found in Appendix~\ref{sec:problem1code}.

After running our R calculations, we found that the average number of bike rentals in March 2011 was 2065.968 bikes and that of March 2012 was 5318.548 bikes. The difference between the means of our two samples was -3252.581. The standard deviation of the number of bikes rented in March 2011 was 550.9717, and the standard deviation of that in March 2012 was 1251.1627. From these values, we found our confidence interval to be $(-5932.108, -573.0535)$. In formal terms, we are 95\% confident that the difference between the mean number of bike rentals on days in March 2011 and days in March 2012 lies within the interval ranging from $-5932.108$ to $-573.0535$.  

Although this is a very wide ranging interval, we still were able to make inferences about the bike rental trends in March 2011 versus the trends in March 2012. Being that we subtracted the sample mean of the bike rentals in March 2012 from that of the bike rentals in March 2011, we inferred that there were significantly more bike rentals in March 2012 than there were in March 2011. This is because the entirety of the interval lies below 0. In the next section, we used a proportion of warmer days in the same two months to see if temperature could have influenced the increase in the number of bike rentals from March 2011 to March 2012.

\subsection{Part B: Comparison of Two Proportions}
\label{subsec:1b}
We wanted to compare the proportion of warmer than average days in March 2011 to those in March 2012. We constructed a confidence interval to estimate the difference between population proportions of the number of warmer days in March 2011 and March 2012. Again, we defined our random variables and then constructed the confidence interval. 
\begin{itemize}
	\item $\hat{p_1}$: the sample proportion of warmer days in March 2011
	\item $\hat{p_2}$: the sample proportion of warmer days in March 2012
	\item $s_{1}^{2}$: the standard deviation of the proportion of warmer days in March 2011
		\subitem Mathematical expression: $s_{1}^{2} =\hat{p_1}(1 - \hat{p_1})$
	\item $s_{2}^{2}$: the standard deviation of the proportion of warmer days in March 2012
		\subitem Mathematical expression: $s_{2}^{2} = \hat{p_2}(1 - \hat{p_2})$
\end{itemize}
The random variables $\hat{p_1}$ and $\hat{p_2}$ are independent of one another. The model that we used to calculate the confidence interval for the difference in the two proportions was:
\begin{equation}
\hat{p_1} - \hat{p_2} \pm (1.96) \sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}} 
\end{equation}
\begin{equation}
= \hat{p_1} - \hat{p_2} \pm (1.96) \sqrt{\frac{\hat{p_1}(1 - \hat{p_1})}{n_1}+\frac{\hat{p_1}(1 - \hat{p_1})}{n_2}}
\end{equation}
\dots where $n_1$ and $n_2$ are the number of days in March 2011 and March 2012 (respectfull) during which the temperature was warm. We defined a "warmer day" to be one in which the temperature rose above 12.5 degrees Celsius, which translated to be 0.3 in the UCI dataset. The R code that was developed to evaluate the above expression can be found in Appendix~\ref{sec:problem1code}.

In our calculation we found that the proportion of warmer days in March 2011 was 0.5806452 and that the proportion of warmer days in March 2012 was 0.9032258. The difference between the proportions of our two samples was found to be 0.3225833. The standard deviation of the proportion of warmer days in March 2011 was 0.4934535, and the standard deviation of the proportion of warmer days in March 2012 was 0.2956500. The resulting confidence interval was $(-0.5250816, -0.1200797)$. We can say that we are 95\% confident that the difference between the population proportions for warmer days in the months of March 2011 and March 2012 lies within the interval ranging from $-0.5250816$ to  $-0.1200797$.

These two confidence intervals show that there could be a relationship between the proportion of warmer days and the number of bike rentals in the month of March. We can see that both the proportion of warmer days and the number of bike rentals in March 2012 were greater than that of March 2011, which suggests that warmer weather could have influenced more people to rent bikes. Although it makes intuitive sense that there is a relationship between warmer weather and an increase in bike rentals, our calculations cannot ensure that warmer weather was, in fact, the reason why there were more people renting bikes. We can only say that there is a potential relationship, given that the confidence intervals indicate as such. 
\pagebreak



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Problem 2}
\label{sec:problem2}
\subsection{Part A}
\label{subsec:2a}
In this part we realized that the casual, registered and dtedate attributes could not be included in our set of predictor variables. This is because casual and registered were both types of ridership, which meant that they were subsets of the data for the response variable cnt, which is the number of rentals of bikes for that particular day. The attribute dteday wasn't even a numerical data type, and therefore could not be included. All other attributes were included in our linear model. The output of the "summary()" function for this model can be seen in Appendix~\ref{subsec:problem2aoutput}, and the code for this part can be seen in Appendix~\ref{sec:problem2code}.

\subsection{Part B}
\label{subsec:2b}
For this part, we formed a model from the training data, and used R's "predict()" function to form a vector of predictions from our validation data. We then calculated the difference between the actual values of the validation set and the predicted values. We then calculated the mean, the minimum value, and the maximum value of the set of differences to get an idea for how close our model was to predicting the actual value of the validation data. Please see Appendix~\ref{sec:problem2code} for the code from Part B. Part C and D will explore the output of this code in detail.   

\subsection{Part C}
\label{subsec:2c}
We fit a linear model to our training set using R's "lm()" function to produce estimates of the coefficients for our linear model from the sample data, which we denote as $\hat{\beta}_{i}$. The output produced by R's "summary()" function can be found in Appendix~\ref{subsec:problem2coutput}.

The first coefficient returned was the intercept value, which we called $\hat{\beta}_{0}$. The estimates for the remaining coefficients represent how each predictor variable affect the response variable. We denoted these as $\hat{\beta}_{i}$, where $i=1,2,...,11$. These values helped us estimate average bike ridership from our sample data. The linear model of our estimated regression is
\begin{equation}
\text{mean count} = \hat{\beta}_0 + \hat{\beta}_1 \text{season} + \hat{\beta}_2 \text{yr} + \hat{\beta}_3\text{mnth} + \hat{\beta}_4\text{holiday} + \hat{\beta}_5\text{weekday} + \hat{\beta}_6\text{workingday} +  \dots
\end{equation}
\begin{equation}
\dots \hat{\beta}_7 \text{weathersit} + \hat{\beta}_8 \text{temp} + \hat{\beta}_9 \text{atemp} + \hat{\beta}_{10} \text{hum} + \hat{\beta}_{11} \text{windspeed}
\end{equation}

The above gives a sample estimate of the population bike ridership values. Looking at the estimate values for the coefficients was saw that there were both positive and negative values. The negative coefficients indicated attributes that resulted in a decrease of bike ridership. For example, the estimate for the coefficient of holidays came out to be -380.192. This suggested bike ridership had decreased if it was a holiday, likely because people chose to spend their holidays doing something other than cycling. The coefficients that were positive values indicated attributes that resulted in an increase of bike ridership. For example, the estimate for temp came to be 487.505, which indicated that average bike ridership as the temperature got warmer.

To get an idea of how accurate our estimate was, we could use the standard error of each of $\hat{\beta}_i$ to calculate a 95\% confidence interval. This would tell us that we are 95\% confident that the true predictor for that particular coefficient was in that interval. The R-squared value tells us that we can predict bike ridership from these eleven coefficients about 76.31\% of the time. 

\subsection{Part D}
\label{subsec:2d}
We added two interaction terms and one quadratic term to the linear model. Our output can be viewed in Appendix~\ref{subsec:problem2doutput}. The interaction terms were temp and workingday. We used temp and workingday in our linear model to demonstrate the bike ridership decreased on days in which the temperature was hot, likely because workers want to avoid a difficult commute in the heat. The other interaction terms are  mnth and weathersit. We combined mnth and weathersit as interaction terms because we thought that later months, coupled with poor weather conditions, led to a lower number of bike rentals. Our quadratic term, tempsquared, was used to exaggerate the negative effect of harsh temperatures on the number of bike rentals. Compared to part C, our R-squared value was 81.73\%, which demonstrates that this model was a more accurate representation of our sample estimate. 

\subsection{Part E}
\label{subsec:2e}
Our final model included the following attributes: year (yr), temp, humidity (hum), windspeed,tempsquared, spring, summer, fall, raining. Tempsquared is the temp values squared. We chose to do this to place more emphasis on the days that had warmer weather because that seems to be a very large contributing factor to bike ridership. We also decided to break the seasons into spring, summer, and fall because we thought that boolean values for each season would result in a more accurate model. For example, fall was originally flagged as a 3, which was carried into the model calculations. We thought that the numerical values for each season represented them in a biased way. For instance, winter carried a value four times larger than spring, but in reality, all seasons are of equal value to our model. By adding these new attributes, we made spring, summer, and fall boolean values so that the calculations are unbiased. We intentionally omitted winter because it would have been redundant to include it among the three other seasons. We could have arbitrarily chosen any other season to be omitted. Lastly, the raining attribute compares weather situations 1 and 2 against 3 and 4 (clear and misty versus light and heavy rain). We theorized that the rain attribute would heavily influence ridership values, and indeed it did. We also chose to exclude the workingday, weekend, weekday, and holiday attributes because we observed their limited impact on the values of R-squared and the mean difference between the predicted and actual validation data. 

\subsection{Part F}
\label{subsec:2f}
 We found that our final model (detailed above) yielded more accurate predictions that previous models since the R-square value reached an approximate value of 0.8436 while using the final model. This meant that we could accurately predict 84.36\% of bike ridership for our sample. Furthermore, the average mean between the predicted values and the actual values was the lowest it had been among all the models. The average difference between our prediction and validation data was approximately 573.579. When deciding which attributes would yeild the best results, we repeatedly ran our model different attributes to gauge whether this difference in mean would increase or decrease, and found the average difference of our final model to yield the lowest values. The output that R produced can be seen in Appendix~\ref{subsec:problem2efoutput}.

\subsection{Part G}
\label{subsec:2g}

\subsection{Part H}
\label{subsec:2h}
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Problem 3}
\label{sec:problem3}
\subsection{Part A: Nonparametric Density Estimation}
\label{subsec:3a}
A plot of the nonparametric density estimation can be viewed in the form of a histogram in Appendix~\ref{sec:problem3aplot}.

\subsection{Part B: Fitting a Parametric Model}
\label{subsec:3b}
In the previous section, we formed a nonparametric estimate of the density of the daily temperature data by constructing a histogram. After analyzing the histogram, we chose to model its density with a normal parametric distribution. The histogram showed two peaks: one peak among the values that represented colder weather and another among those of warmer temperatures. It also showed a dip among values that are somewhere between colder and warmer temperatures. These observations suggested that the daily temperature from 2011 to 2012 in Washington D.C. matched that of a bimodal distribution, however, we theorized that the population temperature, in fact, could have been normally distributed.  

We thought that the frequency of days in which temperature was either extremely cold or extremely warm should be less than that of days in which the temperature was somewhere in between. Our theory came from the idea that climates seem to rarely shift from hot to cold (or vice-versa) in short periods of time, meaning there should be an extended period of time between these periods in which the weather is of moderate temperature. For this reason, we thought there should be a larger number of days of moderate temperature, and that the data should have represented a more normal distribution. 

In the following sections we explain how we fitted our data to a normal parametric model using two different approaches: the Method of Moments approach, and the Maximum Likelihood approach. 

\subsubsection{Method of Moments}
\label{subsubsec:methodofmoments}
The method of moments involves equation population parameters for a particular parametric distribution to its population moments. In the case of the normal distribution these parameters are the mean and the variance. To accurately fit the normal parametric model to our data, we had to determine the method of moments estimators for the mean and variance. We found the first and second theoretical moments to be: 
\begin{equation}
E(X_i) = \mu\ \ \&\ \ E(X_i^2) = \sigma ^ 2 + \mu ^ 2
\end{equation}
The second equation came from manipulating the formula for variance. We cam up with two equations to estimate the moments based on our sample data:
\begin{equation}
E(X_i) = \mu = \frac{1}{n} \sum_{i=1}^n X_i
\end{equation}
\begin{equation}
E(X_i^2) = \sigma ^ 2 + \mu ^ 2 = \frac{1}{n} \sum_{i=1}^{n} X_i^2
\end{equation}
We were able to calculate these values from our sample data of daily temperatures using R. The code that we developed to calculate these moments can be found in Appendix~\ref{sec:problem3code} in the function labeled "PartB()". From our code we determined the method of moments estimator for $E(X)$ to be .4953848 and the estimator for $E(X_i^2)$ to be .2788679 and therefore calculated the variance, $\sigma^2$, to be 0.030473 and the standard deviation, $\sigma$, to be 0.174565. We then used these estimated parameters in our function labeled "PartC()" to get an accurate fit to the data.
 
\subsubsection{Method of Maximum Likelihood}
\label{subsubsec:maximumlikelihood}
The method of maximum likelihood is a more commonly used method to find the likelihood (the probability) of our data values occurring. In the case of our normal distribution, the parameters are mean and standard deviation. To accurately fit the normal parametric model to our data, we had to determine the method of maximum likelihood estimators for the mean and standard deviation. The first step to find the estimators was to determine the likelihood function in terms of the product of the density values. We determined this to be:
\begin{equation}
L=\Pi_{i=1}^{n}\dfrac{1}{\sqrt{2\pi\sigma^2}}e^{-(x_i-\mu)^2/(2\sigma^2)}
\end{equation}
We can simplify this equation into:
\begin{equation}
L=(2\pi\sigma^2)^{-n/2}e^{-\dfrac{1}{2\sigma^2}\sum_{i}(x_i-\mu)^2}
\end{equation}

However, it is usually easier to maximize the log likelihood of a normal distribution. We determined this to be:
\begin{equation}
l(\mu,\sigma) = -\frac{n}{2}log(2\pi) - nlog(\sigma) - \frac{1}{2\sigma^{2}}\sum_{i}(x_i-\mu^2)
\end{equation} 

From here we were able to calculate the values from our sample data of daily temperature using R's mle() function. The code that we developed to calculate these moments can be found in Appendix~\ref{sec:problem3code} in the function labeled "PartB()". From our code we determined the method of maximum likelihood estimator for the mean, $\mu$, to be .4953848 and the estimator for the standard deviation, $\sigma$, to be .1829285. 


\subsection{Part C: Plotting Parametric-Model Curves}
\label{subsec:3c}
We plotted our two parametric model curves on top of the nonparametric density estimation (histogram), and found them to both be very similar. The calculated values of $\mu$ and $\sigma$ were very similar between the Method of Moments and the Method of Maximum Likelihood. In Appendix~\ref{sec:problem3plots} you can find our plots for Method of Moments and Method of Maximum Likelihood superimposed on our plot from "Part A()". The parametric curve for Method of Moments in Appendix~\ref{subsesc:problem3moments} is drawn in red and the curve for Method of Maximum Likelihood in Appendix~\ref{subsesc:problem3cmaximumlikelihood} is drawn in blue. The graph of Appendix~\ref{subsesc:problem3ccombined} shows a curve in purple, which includes the plot of Method of Moments and Method of Maximum Likelihood and shows us that both these methods calculated the same mean and standard deviations for the normal distribution.

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\appendix
\section{Problem 1 Code}
\label{sec:problem1code}
\lstinputlisting{Problem1.R}
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Problem 2 Code}
\label{sec:problem2code}
\lstinputlisting{Problem2.R}
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Problem 2 Output}
\label{sec:problem2output}
\subsection{Part A}
\label{subsec:problem2aoutput}
\includegraphics[totalheight=0.65\textheight]{Part2Aoutput}
\subsection{Part C}
\label{subsec:problem2coutput}
\includegraphics[totalheight=0.65\textheight]{Output.jpg}
\subsection{Part D}
\label{subsec:problem2doutput}
\includegraphics[totalheight=0.65\textheight]{Part2Doutput.jpg}
\pagebreak
\subsection{Part E and F}
\label{subsec:problem2efoutput}
\includegraphics[totalheight=0.65\textheight]{Output2PartEF.jpg}
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Problem 3 Code}
\label{sec:problem3code}
\lstinputlisting{Problem3.R}
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Problem 3 Plots}
\label{sec:problem3plots}
\subsection{Part A}
The plot below is the nonparametric estimate of our data set for daily temperatures. 
\newline
\label{sec:problem3aplot}
\includegraphics{Problem3A.pdf}
\newline
\pagebreak

\subsection{Part C: Method of Moments}
\label{subsesc:problem3moments}
The plot below is the parametric estimate of our data set for daily temperatures while using the Method of Moments approach to estimating the population parameters for a Normal Distribution. 
\newline
\includegraphics{Problem3CMoments.pdf}
\newline
\pagebreak

\subsection{Part C: Maximum Likelihood}
\label{subsesc:problem3cmaximumlikelihood}
The plot below is the parametric estimate of our data set for daily temperatures while using the Method of Maximum Likelihood to estimate the population parameters for a Normal Distribution. 
\newline
\includegraphics{Problem3CMLE.pdf}
\newline
\pagebreak

\subsection{Part C: Combined}
\label{subsesc:problem3ccombined}
\includegraphics{Problem3C.pdf}
\newline
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Group Member Contributions}
\begin{itemize}
	\item William Otwell:
	\begin{itemize}
		\item 
	\end{itemize}
	
	\item Rupali Saiya:
	\begin{itemize}
		\item 
	\end{itemize}
	
	\item Nicholas Layton:
	\begin{itemize}
		\item 
	\end{itemize}
	
	\item Syeda Inamdar:
	\begin{itemize}
		\item 
	\end{itemize}
\end{itemize}
\pagebreak

\end{document}

